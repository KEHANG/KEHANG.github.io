<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 6.036 Project 2: MNIST Classifiers | Kehang Han </title> <meta name="author" content="Kehang Han"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kehang.github.io/blog/2017/mnist-classifiers-exploration/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kehang</span> Han </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/resume_2024.pdf" target="_blank">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">6.036 Project 2: MNIST Classifiers</h1> <p class="post-meta"> Created in April 02, 2017 </p> <p class="post-tags"> <a href="/blog/2017"> <i class="fa-solid fa-calendar fa-sm"></i> 2017 </a>   ·   <a href="/blog/category/basic-project"> <i class="fa-solid fa-tag fa-sm"></i> basic_project</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This project is about digit classification using the <a href="http://yann.lecun.com/exdb/mnist/" rel="external nofollow noopener" target="_blank">MNIST database</a>. It contains 60,000 training digits and 10,000 testing digits. The goal is to practically explore differenet classifiers and evaluate their performances. The exploration ranges from simplest classifier, e.g.,linear regression with softmax for classification, to deep nerual networks.</p> <p>This report will be available online after due date at: <code class="language-plaintext highlighter-rouge">http://kehang.github.io/</code></p> <p>for people (including graders) to review. After grading, the post will be modified to be a standalone report with more background.</p> <p>Package specifications for this project:</p> <ul> <li> <p>OS: Mac</p> </li> <li> <p>python: 3.6.0</p> </li> <li> <p>keras: 2.0.2</p> </li> <li> <p>backend of keras: theano</p> </li> <li> <p>theano: 0.9.0</p> </li> </ul> <h3 id="1-multinomialsoftmax-regression">1. Multinomial/Softmax Regression</h3> <h4 id="part-4-report-base-line-test-error">Part 4: report base-line test error</h4> <p>when <code class="language-plaintext highlighter-rouge">temperature parameter = 1</code>, the test error is 0.1005, implying the linear softmax regression model is able to recognize MNIST digits with around 90%.</p> <h4 id="part-5-explain-temperate-parameter-effects">Part 5: explain temperate parameter effects</h4> <p>Increasing temperature parameter would decrease the probability of a sample \(x^{(i)}\) being assigned a label that has a large \(\theta\), and increase for labels with small \(\theta\). The mathematic explanation is following:</p> \[P_j = \frac{exp(\theta_j x / \tau)}{\sum_k exp(\theta_k x / \tau)}\] \[\frac{\partial log(P_j)}{\partial \tau} = \frac{1}{\tau^2} \Big[ \frac{\sum_k exp(\theta_k x / \tau) \theta_k x}{\sum_k exp(\theta_k x / \tau)} - \theta_j x \Big]\] <p>The first term is the bracket is weighted average of \(\theta x\), so if \(\theta_j x\) is large, the value of the brackect will be negative, leading to negative \(\frac{\partial log(P_j)}{\partial \tau}\).</p> <p>For small \(\theta_j\), \(\theta_j x\) is also small, we have positive \(\frac{\partial log(P_j)}{\partial \tau}\).</p> <h4 id="part-6-temperate-parameter-effect-on-test-error">Part 6: temperate parameter effect on test error</h4> <p>During experimentation, we found the test error increases with temperature parameter as follows:</p> <p>when <code class="language-plaintext highlighter-rouge">temperature parameter = 0.5</code>, the test error is 0.084</p> <p>when <code class="language-plaintext highlighter-rouge">temperature parameter = 1.0</code>, the test error is 0.1005</p> <p>when <code class="language-plaintext highlighter-rouge">temperature parameter = 2.0</code>, the test error is 0.1261</p> <p>Since from Part 5 we know increasing temperature parameter makes probability of large-\(\theta\) label decrease and that of small-\(\theta\) label increase, the probability distribution becomes <strong>more uniform</strong> as temperature parameter icreases.</p> <h4 id="part-7-classify-digits-by-their-mod-3-values">Part 7: classify digits by their mod 3 values</h4> <p>Note: in this part we use <code class="language-plaintext highlighter-rouge">temperature parameter = 1.0</code>.</p> <p>The error rate of the new labels (mod 3) <code class="language-plaintext highlighter-rouge">testErrorMod3 = 0.0768</code>.</p> <p>The error rate of the original labels <code class="language-plaintext highlighter-rouge">testError = 0.1005</code>.</p> <p>The classification error decreases because those examples being classified correctly with original labels will continue being classified correctly with new labels, but those being classified wrongly originally will have a chance to be classified correctly with new labels.</p> <h4 id="part-8-re-train-and-classify-digits-by-their-mod-3-values">Part 8: re-train and classify digits by their mod 3 values</h4> <p>After re-training using the new labels (mod 3), <code class="language-plaintext highlighter-rouge">testErrorMod3 = 0.1872</code>.</p> <h4 id="part-9-explain-test-error-difference-between-part-7-and-8">Part 9: explain test error difference between Part 7 and 8</h4> <p>Compared with <code class="language-plaintext highlighter-rouge">testErrorMod3 = 0.0768</code> in Part 7, re-training makes the test accuracy worse. It is because now in training step, the algorithm has <strong>less information</strong> (very different digits may have same mod 3 labels) with new labels compared with training using 0-9 digit labels.</p> <h3 id="2-classification-using-manually-crafted-features">2. Classification using manually-crafted features</h3> <p>This section we explore one dimensionality reduction approach: PCA and one dimensionality increase approach: polynomial (specifically <code class="language-plaintext highlighter-rouge">cubic</code> version) feature mapping, to see their effects on test error rates.</p> <h4 id="part-3-report-pca-test-error">Part 3: report PCA test error</h4> <p>When we use dimensionality reduction by applying PCA with 18 principal components, the <code class="language-plaintext highlighter-rouge">test error = 0.1483</code>. This error rate is very similar to the original <code class="language-plaintext highlighter-rouge">d=784</code> case. It is because PCA ensures these 18 feature values capture the maximal amount of variation in the original 784-denmensional data.</p> <h4 id="part-4-first-2-principal-components-visualization">Part 4: first 2 principal components visualization</h4> <p>Below is the visualization of the first 2 pricipal components of 100 training data points.</p> <p class="mnist_img"><img src="/assets/mnist_post/img/plotPC_P2p4.png" alt="Alt text"></p> <h4 id="part-5-image-reconstruction-from-pca-representations">Part 5: image reconstruction from PCA-representations</h4> <p>Below are the reconstructions of the first two MNIST images fron their 18-dimensional PCA-representations alongside the originals.</p> <p><strong>MNIST 1st Image</strong> (left: reconstructed, right: original)</p> <p><img src="/assets/mnist_post/img/image_x_first_img_recon.png" alt="Alt text" height="300px" width="360px"> <img src="/assets/mnist_post/img/image_x_first_img.png" alt="Alt text" height="300px" width="360px"></p> <p><strong>MNIST 2nd Image</strong> (left: reconstructed, right: original)</p> <p><img src="/assets/mnist_post/img/image_x_second_img_recon.png" alt="Alt text" height="300px" width="360px"> <img src="/assets/mnist_post/img/image_x_second_img.png" alt="Alt text" height="300px" width="360px"></p> <h4 id="part-6-explicit-cubic-feature-mapping-for-2-dimensional-case">Part 6: explicit cubic feature mapping for 2-dimensional case</h4> <p>For \(x = [x_1, x_2]\) and \(\phi(x)^T \phi(x') = (x^T x' + 1)^3\), we expand and get</p> \[\phi(x)^T \phi(x') = x_1^3{x_1'}^3 + x_2^3{x_2'}^3 + 3 x_1^2{x_1'}^2 x_2 {x_2'} + 3 x_1{x_1'} x_2^2 {x_2'}^2\] \[+ 3 x_1^2{x_1'}^2 + 3 x_2^2{x_2'}^2 + 6 x_1{x_1'} x_2 {x_2'} + 3 x_1 {x_1'} + 3 x_2{x_2'} + 1\] <p>So the corresponding feature vector is</p> \[\phi(x) = (x_1^3, x_2^3, \sqrt{3} x_1^2 x_2, \sqrt{3} x_1 x_2^2, \sqrt{3} x_1^2, \sqrt{3} x_2^2, \sqrt{6} x_1 x_2, \sqrt{3} x_1, \sqrt{3} x_1, 1)^T\] <h4 id="part-7-re-train-using-cubic-feature-mapping">Part 7: re-train using cubic feature mapping</h4> <p>For practical reason, we apply the feature mapping to 10-dimensional PCA representation instead of original 784-dimensional data.</p> <p>With same settings as base-line case (e.g., temperature parameter = 1), the <code class="language-plaintext highlighter-rouge">test error = 0.0865</code>.</p> <h3 id="3-basic-neural-network">3. Basic Neural Network</h3> <h4 id="part-4-improve-learning-rate">Part 4: improve learning rate</h4> <p>Since currently we have constant learning rate, which is not best when approaching the minimum, one way we can do is to reduce learning rate gradually by expressing it as a function of iterations.</p> <h4 id="part-5-too-many-hidden-units">Part 5: too many hidden units</h4> <p>The danger would be overfitting.</p> <h4 id="part-6-training-and-test-error-evolution-against-epochs">Part 6: training and test error evolution against epochs</h4> <p>For training error, it will continue going down with epochs, while for test error, it will first go down and then go up.</p> <h4 id="part-7-optimize-the-number-of-epochs">Part 7: optimize the number of epochs</h4> <p>One way to do is use portion of training data (maybe 10%) as inner validation data, for each epoch we evaluate the inner validation error, if it starts going up consecutively for say, 10 epochs, we stop the training process.</p> <h3 id="4-deep-neural-networks">4. Deep Neural Networks</h3> <h4 id="part-1-fully-connected-neural-networks">Part 1: fully-connected neural networks</h4> <p><strong>(a)</strong> after 10 epochs, the <code class="language-plaintext highlighter-rouge">test accuracy = 0.9172</code>.</p> <p><strong>(b)</strong> My final model architecture (<code class="language-plaintext highlighter-rouge">mnist_nnet_fc_improved.py</code>) has <strong>6 hidden layers</strong> (each has 512 neurons, activation is <code class="language-plaintext highlighter-rouge">ReLU</code>) and 1 output layer (with 10 neurons, activation is <code class="language-plaintext highlighter-rouge">softmax</code>). Optimizer is <code class="language-plaintext highlighter-rouge">SGD(lr=0.03, momentum=0.65, decay=0.0001)</code>. With this architecture, the <code class="language-plaintext highlighter-rouge">test accuracy = 0.9842</code>.</p> <p>Among all the tweaks I’ve tried, increasing the <strong>number of hidden layers</strong> (from 1 hidden layer to 6), the <strong>number of neurons</strong> (from 128 to 512), the <strong>learning rate</strong> (from 0.001 to 0.03, I also modified momentum and decay) help a lot, boosting the test accuracy from <code class="language-plaintext highlighter-rouge">0.9172 to 0.9842</code>.</p> <p>Changing hidden layer activation from <code class="language-plaintext highlighter-rouge">ReLU</code> to <code class="language-plaintext highlighter-rouge">tanh</code> doesn’t make too much difference, but switching to <code class="language-plaintext highlighter-rouge">signmoid</code> really harms test accuracy. Too high or too low decay in learning rate also can damage the accuracy; I believe current choice of decay of 0.0001 is the sweet spot.</p> <h4 id="part-2-convolutional-neural-networks">Part 2: Convolutional neural networks</h4> <p><strong>(a)</strong> A simplest convolutional neural network was constructed in the following order:</p> <ul> <li> <p>A 2D convolutional layer with 32 filters of size 3x3</p> </li> <li> <p>A ReLU activation</p> </li> <li> <p>A max pooling layer with size 2x2</p> </li> <li> <p>A ReLU activation</p> </li> <li> <p>A 2D convolutional layer with 64 filters of size 3x3</p> </li> <li> <p>A ReLU activation</p> </li> <li> <p>A max pooling layer with size 2x2</p> </li> <li> <p>A flatten layer</p> </li> <li> <p>A fully connected layer with 128 neurons</p> </li> <li> <p>A dropout layer with drop probability 0.5</p> </li> <li> <p>A fully connected layer with 10 neurons</p> </li> <li> <p>A softmax activation</p> </li> </ul> <p>The implementation using <code class="language-plaintext highlighter-rouge">keras</code> is list below:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Activation</span><span class="p">(</span><span class="sh">"</span><span class="s">softmax</span><span class="sh">"</span><span class="p">))</span></code></pre></figure> <p>The result is quite encouraging, just one epoch, the <code class="language-plaintext highlighter-rouge">test accuracy</code> reaches <code class="language-plaintext highlighter-rouge">0.9810</code>. But it does take longer to finish one epoch (48 secs, while 4 secs for the Part 1 fully-connected neural networks).</p> <p>To speedup the training time and achieve higher <code class="language-plaintext highlighter-rouge">test accuracy</code>, I set up <a href="/blog/2017/install-CUDA-cuDNN-on-Red-Hat/">CUDA drivers in a accessible GPU</a> and ran the same ConvNN for <code class="language-plaintext highlighter-rouge">15 epochs</code>. Here’s the training log from GPU:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash">Using Theano backend.
Using cuDNN version 5110 on context None
Mapped name None to device cuda: Quadro K2200 <span class="o">(</span>0000:03:00.0<span class="o">)</span>
Train on 54000 samples, validate on 6000 samples
Epoch 1/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.2062 - acc: 0.9346 - val_loss: 0.0555 - val_acc: 0.9822
Epoch 2/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0771 - acc: 0.9771 - val_loss: 0.0408 - val_acc: 0.9878
Epoch 3/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0577 - acc: 0.9820 - val_loss: 0.0351 - val_acc: 0.9887
......
Epoch 12/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0193 - acc: 0.9934 - val_loss: 0.0346 - val_acc: 0.9912
Epoch 13/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0317 - val_acc: 0.9912
Epoch 14/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0157 - acc: 0.9945 - val_loss: 0.0345 - val_acc: 0.9912
Epoch 15/15
54000/54000 <span class="o">[================]</span> - 6s - loss: 0.0151 - acc: 0.9948 - val_loss: 0.0348 - val_acc: 0.9905
8832/10000 <span class="o">[===========&gt;</span>....] - ETA: 0sLoss on <span class="nb">test set</span>:0.0324026019065 Accuracy on <span class="nb">test set</span>: 0.9902</code></pre></figure> <p>It achieves <code class="language-plaintext highlighter-rouge">99.02%</code> of test accuracy after 15 epochs, and each epoch takes only <code class="language-plaintext highlighter-rouge">6 secs</code>.</p> <h3 id="5-classification-for-overlapping-multi-digit-mnist">5. Classification for overlapping multi-digit MNIST</h3> <h4 id="pre-step-data-representation-and-model-arguments">Pre-step: data representation and model arguments</h4> <p>Training set has 40,000 examples, each example is 42x28 size image, which has two labels indicating two overlapping digits in the image. Each label is a vector of length 10.</p> <p>Testing set has 4,000 examples, each example is also 42x28 size image, which also has two labels indicating two overlapping digits in the image. Each label is a vector of length 10.</p> <p><code class="language-plaintext highlighter-rouge">y_train[0]</code> is the fisrt digits in the training images, while <code class="language-plaintext highlighter-rouge">y_train[1]</code> is the second.</p> <p>For <code class="language-plaintext highlighter-rouge">model.compile</code>, <code class="language-plaintext highlighter-rouge">loss='categorical_crossentropy'</code> means the loss function type is cross entropy function for both outputs, <code class="language-plaintext highlighter-rouge">optimizer='sgd'</code> means algorithm is using stochastic gradient descent method to learn, <code class="language-plaintext highlighter-rouge">metrics=['accuracy']</code> means accuracy is used as metric, and <code class="language-plaintext highlighter-rouge">loss_weights=[0.5, 0.5]</code> means the two labels are equally treated when calculating loss.</p> <p>For <code class="language-plaintext highlighter-rouge">model.fit</code>, <code class="language-plaintext highlighter-rouge">X_train, [y_train[0], y_train[1]]</code> are the training data and their labels, <code class="language-plaintext highlighter-rouge">epochs=nb_epoch</code> means total epochs for training, <code class="language-plaintext highlighter-rouge">batch_size=batch_size</code> means training is using mini-batch gradient descent approach, and <code class="language-plaintext highlighter-rouge">verbose=1</code> is setting the logging verbosity.</p> <h4 id="five-explored-models">Five explored models</h4> <p><strong>model1: mlp</strong> (coded in <code class="language-plaintext highlighter-rouge">mlp.py</code>)</p> <p>The architecture is shown below, with one hidden layer of 64 neurons (<code class="language-plaintext highlighter-rouge">relu</code> activation).</p> <p class="srs_img"><img src="/assets/mnist_post/img/mlp.png" alt="Alt text" height="250px" width="230px"></p> <p>After training 30 epochs, the test accuracy for <code class="language-plaintext highlighter-rouge">1st label</code> is <code class="language-plaintext highlighter-rouge">0.9378</code>, for <code class="language-plaintext highlighter-rouge">2nd label</code> is <code class="language-plaintext highlighter-rouge">0.9278</code>. Total training time is 3 secs/epoch, total 90 secs (run on NVIDIA Quadro K2200 GPU, same for all the other four models).</p> <p><strong>model2: mlp2</strong> (coded in <code class="language-plaintext highlighter-rouge">mlp2.py</code>)</p> <p>The architecture is shown below, with <code class="language-plaintext highlighter-rouge">6 hidden layer</code> of 64 neurons (<code class="language-plaintext highlighter-rouge">relu</code> activation).</p> <p class="srs_img"><img src="/assets/mnist_post/img/mlp2.png" alt="Alt text" height="420px" width="180px"></p> <p>After training 30 epochs, the test accuracy for <code class="language-plaintext highlighter-rouge">1st label</code> is <code class="language-plaintext highlighter-rouge">0.9503</code>, for <code class="language-plaintext highlighter-rouge">2nd label</code> is <code class="language-plaintext highlighter-rouge">0.9429</code>. Total training time is 4 secs/epoch, total 120 secs.</p> <p><strong>model3: conv</strong> (coded in <code class="language-plaintext highlighter-rouge">conv.py</code>)</p> <p>The architecture is shown below. The first <code class="language-plaintext highlighter-rouge">Conv2D</code> has 8 filters, and second has 16 filters. <code class="language-plaintext highlighter-rouge">SGD</code> is the optimizer.</p> <p class="srs_img"><img src="/assets/mnist_post/img/conv.png" alt="Alt text" height="420px" width="200px"></p> <p>After training 15 epochs, the test accuracy for <code class="language-plaintext highlighter-rouge">1st label</code> is <code class="language-plaintext highlighter-rouge">0.9828</code>, for <code class="language-plaintext highlighter-rouge">2nd label</code> is <code class="language-plaintext highlighter-rouge">0.9755</code>. Total training time is 14 secs/epoch, total 210 secs.</p> <p><strong>model4: conv2</strong> (coded in <code class="language-plaintext highlighter-rouge">conv2.py</code>)</p> <p>The architecture is exactly same as model <code class="language-plaintext highlighter-rouge">conv</code>. The difference is <code class="language-plaintext highlighter-rouge">adam</code> is the optimizer.</p> <p>After training 15 epochs, the test accuracy for <code class="language-plaintext highlighter-rouge">1st label</code> is <code class="language-plaintext highlighter-rouge">0.9869</code>, for <code class="language-plaintext highlighter-rouge">2nd label</code> is <code class="language-plaintext highlighter-rouge">0.9822</code>. Total training time is 14 secs/epoch, total 210 secs.</p> <p><strong>model5: conv3</strong> (coded in <code class="language-plaintext highlighter-rouge">conv3.py</code>)</p> <p>The architecture is exactly same as model <code class="language-plaintext highlighter-rouge">conv</code>. The difference is that the first <code class="language-plaintext highlighter-rouge">Conv2D</code> has 32 filters, and second has 64 filters</p> <p>After training 15 epochs, the test accuracy for <code class="language-plaintext highlighter-rouge">1st label</code> is <code class="language-plaintext highlighter-rouge">0.9890</code>, for <code class="language-plaintext highlighter-rouge">2nd label</code> is <code class="language-plaintext highlighter-rouge">0.9869</code>. Total training time is 39 secs/epoch, total 585 secs.</p> <h4 id="thoughts-on-model-selection">Thoughts on model selection</h4> <p>It seems that convolutional neural networks are more effective in learning images than fully connected neural networks. Model <code class="language-plaintext highlighter-rouge">mlp</code> and <code class="language-plaintext highlighter-rouge">mlp2</code> can only achieve test accuracy around <code class="language-plaintext highlighter-rouge">0.95</code>, while <code class="language-plaintext highlighter-rouge">conv</code>, <code class="language-plaintext highlighter-rouge">conv2</code> and <code class="language-plaintext highlighter-rouge">conv3</code> can easily achieve beyond <code class="language-plaintext highlighter-rouge">0.98</code>.</p> <p>For fully connected neural networks, adding more hidden layers seems helpful at least from 1 hidden layer to 6 hidden layers.</p> <p>Sometime optimizer can make a difference as well, e.g., here using <code class="language-plaintext highlighter-rouge">adam</code> optimizer is more effective than <code class="language-plaintext highlighter-rouge">SGD</code> to reach minimum.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/battle-tested-llm-training-basic-input-pipeline/">Battle-Tested LLM Training: From Dataset to Data Iterator</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/battle-tested-llm-training-multihost-input-pipeline/">Battle-Tested LLM Training: Multi-host Input Pipeline</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/a-desk-that-listens/">A Desk That Listens</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/a-desk-with-its-own-schedule/">A Desk with Its Own Schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/named-entity-recognition-part2/">Demystifying Named Entity Recognition - Part II</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Kehang Han. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: August 19, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-battle-tested-llm-training-from-dataset-to-data-iterator",title:"Battle-Tested LLM Training: From Dataset to Data Iterator",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/battle-tested-llm-training-basic-input-pipeline/"}},{id:"post-battle-tested-llm-training-multi-host-input-pipeline",title:"Battle-Tested LLM Training: Multi-host Input Pipeline",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/battle-tested-llm-training-multihost-input-pipeline/"}},{id:"post-a-desk-that-listens",title:"A Desk That Listens",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/a-desk-that-listens/"}},{id:"post-a-desk-with-its-own-schedule",title:"A Desk with Its Own Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/a-desk-with-its-own-schedule/"}},{id:"post-demystifying-named-entity-recognition-part-ii",title:"Demystifying Named Entity Recognition - Part II",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/named-entity-recognition-part2/"}},{id:"post-demystifying-named-entity-recognition-part-i",title:"Demystifying Named Entity Recognition - Part I",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/named-entity-recognition/"}},{id:"post-molecular-convnet-in-property-prediction",title:"Molecular ConvNet in Property Prediction",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/machine-learning-in-molecular-property-prediction/"}},{id:"post-6-036-project-2-mnist-classifiers",title:"6.036 Project 2: MNIST Classifiers",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/mnist-classifiers-exploration/"}},{id:"post-install-cuda-and-cudnn-on-red-hat",title:"Install CUDA and cuDNN on Red Hat",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/install-CUDA-cuDNN-on-Red-Hat/"}},{id:"post-smart-review-summarization-project",title:"Smart Review Summarization Project",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/smart-review-summarization-project/"}},{id:"post-reactor-optimization-with-fmincon",title:"Reactor Optimization with fmincon!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/fmincon-tutorial/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6B%65%68%61%6E%67%68%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=ON8jkO0AAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>