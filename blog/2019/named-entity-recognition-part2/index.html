<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Demystifying Named Entity Recognition - Part II | Kehang Han </title> <meta name="author" content="Kehang Han"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kehang.github.io/blog/2019/named-entity-recognition-part2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kehang</span> Han </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/resume_2024.pdf" target="_blank">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Demystifying Named Entity Recognition - Part II</h1> <p class="post-meta"> Created in June 15, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/category/nlp"> <i class="fa-solid fa-tag fa-sm"></i> nlp,</a>   <a href="/blog/category/explained"> <i class="fa-solid fa-tag fa-sm"></i> explained</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a continuation for <a href="/blog/2019/named-entity-recognition/">Demystifying Named Entity Recognition - Part I</a>, in this post I’ll discuss popular models available in the field and try to cover:</p> <ul> <li> <p>popular <strong>traditional</strong> models</p> </li> <li> <p><strong>deep learning</strong> models</p> </li> <li> <p>python libraries</p> </li> </ul> <p>Over the history of <a href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="external nofollow noopener" target="_blank">NER</a>, there’s been three major approaches: grammar-based, dictionary-based and machine-learning-based. Grammar-based approach produces a set of empirical rules hand-crafted by experienced computational linguists, usually takes months of work. Dictionary-based approach basically organizes all the known entities into a lookup table, which can be used to detect whether a candidate belongs to a defined category or not. By design it doesn’t work well with newly invented entities. Machine-learning-based approach typically needs annotated data, but doesn’t necessarily rely on domain experts to come up with rules or fail on unseen entities.</p> <p>This post focuses only on machine-learning based models.</p> <h2 id="1-popular-traditional-models">1. Popular traditional models</h2> <p>The traditional models we’ll discuss here are <a href="https://en.wikipedia.org/wiki/Maximum-entropy_Markov_model" rel="external nofollow noopener" target="_blank">MEMM</a>, <a href="https://en.wikipedia.org/wiki/Conditional_random_field" rel="external nofollow noopener" target="_blank">CRF</a>. They are very popularly used before deep learning models entered the scene.</p> <h3 id="11-memm">1.1 MEMM</h3> <p>We’ve covered the details of MEMM in the <a href="/blog/2019/named-entity-recognition/">previous post</a>. The key idea of the MEME approach is to model the <strong>conditional probability</strong> of tag sequenece for a given sentence with Markov assumption:</p> \[p(y_1...y_n | x_1...x_n) = \prod_{i=1}^{n} p(y_i |y_{i-1}, x_1...x_n)\] <p>We then model \(p(y_i | y_{i-1}, x_1...x_n)\) using local environment:</p> \[p(y_i | y_{i-1}, x_1...x_n) = \frac{\exp({\underline{\theta} \cdot \underline{f}(y_{i-1}, y_i, x_1...x_n)})}{\sum_{y'}{\exp({\underline{\theta} \cdot \underline{f}(y_{i-1}, y', x_1...x_n)})}}\] <p><strong>In inference</strong>, we use <em>Viterbi</em> algorithm to get best-fitting tag sequence for a given sentence. Details can be found in 2.2.1 section of the <a href="/blog/2019/named-entity-recognition/">previous post</a>.</p> <p><strong>In training</strong>, we use <em>maximum likelihood estimation</em> to get optimal \(\underline{\theta}\) that</p> \[max_{\underline{\theta}} \prod_{j=1}^{N} p(\underline{x}^j | \underline{y}^j)\] <p>where \(\underline{x}^j, \underline{y}^j\) are the \(j^{th}\) sentence and corresponding tag sequence (the whole training dataset has \(N\) examples).</p> <h3 id="12-crf">1.2 CRF</h3> <p>Instead of \(p(y_i | y_{i-1}, \underline{x})\) , Conditional Random Field (CRF) approach chooses to directly model \(p(\underline{y} | \underline{x})\):</p> \[p(\underline{y} | \underline{x}) = \frac{\exp({\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})})}{\sum_{\underline{y}'}{\exp({\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y}')})}}\] <p>The main challenge in direct modeling is that the denominator is sum of \(K^n\) terms where \(K\) is the number of tag label types and \(n\) is the length of sentence to tag. This is a much larger number than that in MEMM - \(p(y_i | y_{i-1}, x_1...x_n)\) has just \(K\) terms in the denominator.</p> <h4 id="121-inference">1.2.1 Inference</h4> <p>During inference, we are only interested in the \(\underline{y}^{*}\) that gives the highest probability rather than the highest probability itself:</p> \[\underline{y}^{*} = \text{arg} \max_{\underline{y}} p(\underline{y} | \underline{x}) = \text{arg} \max_{\underline{y}}\exp({\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})}) = \text{arg} \max_{\underline{y}}{\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})}\] <p>If using brutal force, we have to evaluate \(\exp({\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})})\) for \(K^n\) times.</p> <p>Fortunately, if we add a little structure into \(\underline{F}(\underline{x}, \underline{y})\), which I’m going to talk about next, we can bring the exponential complexity - \(O(K^n)\) down to linear complexity - \(O(K^2n)\).</p> <p>The structure added in CRF is:</p> \[\underline{F}(\underline{x}, \underline{y}) = \sum_{i=1}^n \underline{f}(\underline{x}, y_{i-1}, y_i)\] <p>To maximize \(\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})\), we define a partial score as we did in 2.2.1 section of the <a href="/blog/2019/named-entity-recognition/">previous post</a>:</p> \[s_{partial, k}(y_{1...k}) = \underline{\Theta} \cdot \sum_{i=1}^k \underline{f}(\underline{x}, y_{i-1}, y_i)\] <p>If we can maximize any partial score (which turns out not that difficult), then the score we want to acutally maximize, \(\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})\), is just a special case of \(s_{partial, k}\) when \(k=n\).</p> <p>So how to maximize any partial score? Let’s start with \(k=1\), namely \(s_{partial, 1} (y_1)= \underline{\Theta} \cdot \underline{f}(\underline{x}, y_1)\).</p> <blockquote> <p>This is easy because it’s just a single-variable optimization and \(y_1\) can only have K choices. We also store all the evaluated \(s_{partial, 1} (y_1)\).</p> </blockquote> <p>How about \(k=2\), namely maximize \(s_{partial, 2}(y_1, y_2) = s_{partial, 1}(y_1) + \underline{\Theta} \cdot \underline{f}(\underline{x}, y_1, y_2)\)?</p> <blockquote> <p>We can first fix \(y_2\) and optimize over \(y_1\) dimension. Remember we’ve known \(s_{partial, 1}(y_1)\) evaluated from the previous question. So it takes \(K\) computations to find the optimal \(y_1\) for each \(y_2\) - \(s_{partial, 2}(y_1^*, y_2)\). Then pick the \(y_2^*\) which has maximum \(s_{partial, 2}(y_1^*, y_2)\). In total, we need perform \(K^2\) evaluations. We also store all the \(s_{partial, 2}(y_1^*, y_2)\) for future use.</p> </blockquote> <p>How about \(k=3\), namely maximize \(s_{partial, 3}(y_1, y_2, y_3) = s_{partial, 2}(y_1, y_2) + \underline{\Theta} \cdot \underline{f}(\underline{x}, y_2, y_3)\)?</p> <blockquote> <p>Similar to the previous question, we try to estimate \(s_{partial, 3}(y_1^*, y_2^*, y_3)\) for each \(y_3\) using \(s_{partial, 3}(y_1^*, y_2^*, y_3) = \max_{y_2}(s_{partial, 2}(y_1^*, y_2) + \underline{\Theta} \cdot \underline{f}(\underline{x}, y_2, y_3))\). We also carry out \(K\) evaluation per \(y_3\), thus totally \(K^2\) evaluations for all possible \(y_3\). We store \(s_{partial, 3}(y_1^*, y_2^*, y_3)\) for future use (e.g., when \(k=4\)).</p> </blockquote> <p>By doing this all the way to \(k=n\), we can get \(\max_{\underline{y}}{\underline{\Theta} \cdot \underline{F}(\underline{x}, \underline{y})}\) with roughly \(K^2n\) evaluations.</p> <h4 id="122-training">1.2.2 Training</h4> <p>Similar to MEMM, we can also use <em>maximum likelihood estimation</em> to get optimal \(\underline{\Theta}\) that</p> \[max_{\underline{\Theta}} \prod_{j=1}^{N} p(\underline{x}^j | \underline{y}^j)\] <p>where \(\underline{x}^j, \underline{y}^j\) are the \(j^{th}\) sentence and corresponding tag sequence (the whole training dataset has \(N\) examples). More details on training algorithm can be found in Page 10 of <a href="http://www.cs.columbia.edu/~mcollins/crf.pdf" rel="external nofollow noopener" target="_blank">Michael Collins’s CRF note</a>.</p> <h2 id="2-deep-learning-models">2. Deep learning models</h2> <p>The deep learning models we’ll discuss here are <a href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="external nofollow noopener" target="_blank">LSTM</a>, <a href="https://arxiv.org/abs/1508.01991" rel="external nofollow noopener" target="_blank">BiLSTM-CRF</a>, <a href="https://arxiv.org/pdf/1810.04805.pdf" rel="external nofollow noopener" target="_blank">Bert</a>.</p> <h3 id="21-lstm">2.1 LSTM</h3> <h4 id="211-architecture">2.1.1 Architecture</h4> <p class="srs_img"><img src="/assets/ner_post/img/lstm.png" alt="Alt text" width="100%"></p> <p>In the setting of LSTM, each token \(x_i\) is fed to a LSTM unit, which outputs a \(o_i\). \(o_i\) models log probabilities of all possible tags at i-th position, so it has dimension of \(K\).</p> \[o_i = \begin{bmatrix}log P(y_i = PER | \underline{x})\\log P(y_i = ORG | \underline{x})\\...\\log P(y_i = MISC | \underline{x})\end{bmatrix}\] <h4 id="212-inference">2.1.2 Inference</h4> <p>The inference in LSTM is very simple: \(y_i\) = the tag with highest log probability at i-th position.</p> \[y_i^* = argmax_k o_{i,k}\] <p>which indicates the prediction of i-th position only utilizes the sentence information up to i-th token - only the left side of the sentence is used for tag prediction at i-th position. BiLSTM is designed to provide context information from both sides, which will be seen in next section.</p> <h4 id="213-training">2.1.3 Training</h4> <p>Like all the other neural network training, LSTM training uses <strong>Stochastic Gradient Descent</strong> algorithm. Loss function adopts <strong>negative log likelihood</strong>. For a data point \((\underline{x^j}, \underline{y^j})\), we have its loss calculated as:</p> \[L_j = -\sum_{i=1}^{n_j} o_i^j[y_{i}^j]\] <p>where \(n_j\) is the length of the sentence \(x^j\), \(o_i^j\) is the LSTM output at i-th position and \(y_i^j\) is the ground truth tag at i-th position.</p> <p><strong>Total loss</strong> is the mean of all the individual losses.</p> \[L = \frac{1}{N}\sum_{j=1}^N L_j\] <p>where \(N\) is the total number of training examples.</p> <h3 id="22-bilstm">2.2 BiLSTM</h3> <p class="srs_img"><img src="/assets/ner_post/img/bilstm.png" alt="Alt text" width="120%"></p> <p>BiLSTM stands for bi-directional LSTM, which provides sequence information from both directions. Because of that, BiLSTM is more powerful than LSTM. Except the bi-directional component, the meaning of network output, inference, and training loss are same as LSTM.</p> <h3 id="23-bilstm-crf">2.3 BiLSTM-CRF</h3> <p>BiLSTM captures contextual information around i-th position. But at each position, BiLSTM predicts tags basically in an independent fashion. There’s cases where some adjacent positions are predicted with tags which do not usually appear together in reality. For example, I-PER tag should not follow B-ORG. To account for this kind of interactions between adjacent tags, Conditional Random Field (CRF) is introduced to BiLSTM.</p> <h4 id="231-architecture">2.3.1 Architecture</h4> <p class="srs_img"><img src="/assets/ner_post/img/bilstm-crf.png" alt="Alt text" width="120%"></p> <p>where \(o_i\) models <strong>emission scores</strong> of all possible tags at i-th position and \(y_i^*\) is the best tag for i-th position which collectively achieves highest sequence score.</p> \[o_i = \begin{bmatrix} score_{emission}(y_i = PER | \underline{x})\\score_{emission}(y_i = ORG | \underline{x})\\...\\score_{emission}(y_i = MISC | \underline{x})\end{bmatrix}\] <p>CRF layer also learns a transition matrix \(A\) which stores transition scores between any possible pair of tag types.</p> <h4 id="231-inference">2.3.1 Inference</h4> <p>Same as the inference in CRF section, given a trained network and sentence \(\underline{x}\), any sequence \(\underline{s}\) will have a score.</p> \[score(\underline{x}, \underline{s}) = \sum_{i=1}^n o_i[s_i] + A[s_{i-1}][s_i]= \sum_{i=1}^n \phi(\underline{x}, s_{i-1}, s_i)\] <p>The score is a sum of contributions from token level. i-th position has contribution of \(\phi(\underline{x}, s_{i-1}, s_i) = o_i[s_i] + A[s_{i-1}][s_i]\), where the first term is emission score and second term is transition score.</p> <p>To find the tag sequence \(\underline{y}^*\) achieving highest score, we need to use dynamic programming.</p> <p>Define sub problem \(DP(k,t)\) to be the max score accumulated from 1st position to \(k\)-th position with the \(k\)-th position tag being \(t\), detailed as follows:</p> \[DP(k, t) = \max \limits_{\underline{s}\in S^k:s_k=t} \sum_{i=1}^k \phi(\underline{x}, s_{i-1}, s_i)\] <p>The recursion would be:</p> \[DP(k+1, t) = \max \limits_{t'} [DP(k, t') + \phi(\underline{x}, t', t)]\] <p>The original problem is then</p> \[score(\underline{x}, \underline{y}^*) = \max \limits_{t} DP(n, t)\] <p>We can always use <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/lecture-videos/MIT6_006F11_lec20.pdf" rel="external nofollow noopener" target="_blank">parent pointers</a> to retrieve the corresponding best sequence \(\underline{y}^*\).</p> <h4 id="232-training">2.3.2 Training</h4> <p>Loss function for BiLSTM-CRF also adopts <strong>negative log likelihood</strong>. For a data point \((\underline{x^j}, \underline{y^j})\), we have its loss calculated as:</p> \[L_j = -log P(\underline{y}^j | \underline{x}^j) = - log \frac{exp(score(\underline{x}^j, \underline{y}^j))}{\sum \limits_{\underline{y'}^j} exp(score(\underline{x}^j, \underline{y'}^j))}\] \[= - score(\underline{x}^j, \underline{y}^j) + log \sum \limits\_{\underline{y'}^j} exp(score(\underline{x}^j, \underline{y'}^j))\] <p>where the first term is easy to calculate via a forward pass of the network and the second term needs more care. Let’s define that term (without log) as \(Z\), which is exponential sum of scores of all the possible sequences \(\underline{s}\) of length \(n\).</p> \[Z = \sum \limits_{\underline{s} \in S^n} exp(score(\underline{x}, \underline{s})) = \sum \limits_{\underline{s} \in S^n} exp(\sum_{i=1}^{n} \phi(\underline{x}, s_{i-1}, s_i))\] \[= \sum \limits_{\underline{s} \in S^n} \prod_{i=1}^{n} exp(\phi(\underline{x}, s_{i-1}, s_i)) = \sum \limits_{\underline{s} \in S^n} \prod_{i=1}^{n} \psi(\underline{x}, s_{i-1}, s_i)\] <p>To calculate \(Z\), we need to use dynamic programming again. This time the sub-problem \(DP(k,t)\) is the exponential sum of scores of all possible sequences of length \(k\) with last tag \(s_k = t\):</p> \[DP(k,t)= \sum \limits*{\underline{s} \in S^k: s_k=t} \prod*{i=1}^{k} \psi(\underline{x}, s\_{i-1}, s_i)\] <p>The recursion would be:</p> \[DP(k+1,t) = \sum \limits\_{t'} DP(k,t')\cdot \psi(\underline{x}, t', t)\] <p>The original problem is then</p> \[Z = \sum \limits_{t} DP(n,t)\] <p>Via this way, individual loss \(L_j\) is calculated and then batch loss by averaging the individual losses in the batch.</p> <h3 id="24-bert">2.4 Bert</h3> <p>Recent research on BERT provides an option for NER modeling. Despite of the complexity of the BERT model architecture, in the context of NER it can be regarded as an advanced version of our BiLSTM model - replacing the LSTM with multiple <a href="http://jalammar.github.io/illustrated-transformer/" rel="external nofollow noopener" target="_blank">Transformer Encoder</a> layers.</p> <p class="srs_img"><img src="/assets/ner_post/img/bert.png" alt="Alt text" width="120%"></p> <p>Thus, \(o_i\) still models log probabilities of all possible tags at i-th position.</p> \[o_i = \begin{bmatrix}log P(y_i = PER | \underline{x})\\log P(y_i = ORG | \underline{x})\\...\\log P(y_i = MISC | \underline{x})\end{bmatrix}\] <p>Inference, and training loss are same as LSTM section.</p> <h2 id="3-python-libraries">3. Python libraries</h2> <p>There’s several machine learning based NER repositories in GitHub. I picked some of them here with some comments.</p> <ul> <li> <p><a href="https://github.com/KEHANG/ner/" rel="external nofollow noopener" target="_blank">KEHANG/ner</a>: for English texts, based on PyTorch, has LSTM, BiLSTM, BiLSTM+CRF and Bert models, has released conda package</p> </li> <li> <p><a href="https://github.com/shiyybua/NER" rel="external nofollow noopener" target="_blank">shiyybua/NER</a>: for Chinese texts, based on Tensorflow, only BiLSTM+CRF model, no packages released</p> </li> <li> <p><a href="https://github.com/Franck-Dernoncourt/NeuroNER" rel="external nofollow noopener" target="_blank">Franck-Dernoncourt/NeuroNER</a>: for English texts, based on Tensorflow, has LSTM model, no package released</p> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/battle-tested-llm-training-input-pipeline/">Battle-Tested LLM Training: The Input Pipeline</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/a-desk-that-listens/">A Desk That Listens</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/a-desk-with-its-own-schedule/">A Desk with Its Own Schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/named-entity-recognition/">Demystifying Named Entity Recognition - Part I</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2017/machine-learning-in-molecular-property-prediction/">Molecular ConvNet in Property Prediction</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Kehang Han. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: August 06, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-battle-tested-llm-training-the-input-pipeline",title:"Battle-Tested LLM Training: The Input Pipeline",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/battle-tested-llm-training-input-pipeline/"}},{id:"post-a-desk-that-listens",title:"A Desk That Listens",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/a-desk-that-listens/"}},{id:"post-a-desk-with-its-own-schedule",title:"A Desk with Its Own Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/a-desk-with-its-own-schedule/"}},{id:"post-demystifying-named-entity-recognition-part-ii",title:"Demystifying Named Entity Recognition - Part II",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/named-entity-recognition-part2/"}},{id:"post-demystifying-named-entity-recognition-part-i",title:"Demystifying Named Entity Recognition - Part I",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/named-entity-recognition/"}},{id:"post-molecular-convnet-in-property-prediction",title:"Molecular ConvNet in Property Prediction",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/machine-learning-in-molecular-property-prediction/"}},{id:"post-6-036-project-2-mnist-classifiers",title:"6.036 Project 2: MNIST Classifiers",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/mnist-classifiers-exploration/"}},{id:"post-install-cuda-and-cudnn-on-red-hat",title:"Install CUDA and cuDNN on Red Hat",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/install-CUDA-cuDNN-on-Red-Hat/"}},{id:"post-smart-review-summarization-project",title:"Smart Review Summarization Project",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/smart-review-summarization-project/"}},{id:"post-reactor-optimization-with-fmincon",title:"Reactor Optimization with fmincon!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/fmincon-tutorial/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6B%65%68%61%6E%67%68%61%6E@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=ON8jkO0AAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>